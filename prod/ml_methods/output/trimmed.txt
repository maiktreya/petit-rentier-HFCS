r$> source("c:\\Users\\70254057\\Desktop\\basic-hub\\petit-rentier-HFCS
    \\prod\\ml_methods\\XGBoost-dummies.R", encoding = "UTF-8")
data.table 1.17.8 using 6 threads (see ?getDTthreads).  Latest news: r-datatable.com
Loading required package: ggplot2
Loading required package: lattice
Garbage collection 23 = 17+2+4 (level 2) ...
115.6 Mbytes of cons cells used (50%)
28.6 Mbytes of vectors used (45%)
[1] "model type rentsbi_K"
[1] "########################--------------------------------------------------------------########################"
                Feature         Gain       Cover   Frequency
                 <char>        <num>       <num>       <num>
 1:              otherp 0.2245752769 0.049566138 0.068627451
 2:           sa0100_FI 0.1593354490 0.042425025 0.015686275
 3:        class_Worker 0.1491253290 0.014417085 0.033921569
 4:      class_Inactive 0.0727623212 0.022767423 0.031960784
 5:            age_0-29 0.0442737346 0.021730265 0.018823529
 6:           sa0100_DE 0.0304120535 0.020824416 0.009607843
 7:           age_30-49 0.0293279428 0.024236873 0.044509804
 8:           sa0100_NL 0.0287888816 0.027169555 0.010196078
 9:             age_+70 0.0275899460 0.032775408 0.046078431
10:    edu_ref_tertiary 0.0274254680 0.025379951 0.042745098
11:           sa0100_IE 0.0241521663 0.020580283 0.007843137
12:               hsize 0.0240918015 0.147760537 0.186666667
13:           age_50-69 0.0226848274 0.014636336 0.030000000
14:             homeown 0.0224624847 0.032503106 0.059411765
15:           sa0100_ES 0.0117749409 0.013624785 0.012549020
16:           sa0100_PL 0.0098551423 0.026411365 0.005098039
17:           sa0100_IT 0.0083415037 0.024656526 0.009411765
18:     edu_ref_primary 0.0081427679 0.025753689 0.027254902
19:           sa0100_EE 0.0081353226 0.024425319 0.008039216
20:           sa0100_SK 0.0068994655 0.027460775 0.004901961
21:          head_gendr 0.0067535104 0.036777555 0.069803922
22:           sa0100_HU 0.0065320240 0.027548306 0.012941176
23:           sa0100_GR 0.0058793261 0.022322661 0.005490196
24:              wave_2 0.0047613990 0.018040375 0.035686275
25:           sa0100_LV 0.0045469561 0.019834439 0.005882353
26:           sa0100_SI 0.0044656336 0.022453359 0.006078431
27:           sa0100_BE 0.0035644600 0.011928527 0.006862745
28:   edu_ref_secondary 0.0034860592 0.022967157 0.042352941
29:              wave_1 0.0030733976 0.017607467 0.024901961
30:           sa0100_LT 0.0030061524 0.023797465 0.003333333
31:           sa0100_LU 0.0029415683 0.014368438 0.007450980
32:              wave_3 0.0022736240 0.007764859 0.029411765
33:              wave_4 0.0015161730 0.005368461 0.023725490
34:       class_Manager 0.0014908144 0.013729677 0.012549020
35:           sa0100_MT 0.0013593841 0.013586720 0.007254902
36:           sa0100_PT 0.0010611594 0.012779846 0.010196078
37:           sa0100_AT 0.0010527755 0.012215244 0.005882353
38:           sa0100_CY 0.0008158551 0.015045586 0.004901961
39:           sa0100_HR 0.0007169503 0.017701241 0.003529412
40: class_Self-Employed 0.0003330316 0.014399765 0.005294118
41:      class_Employer 0.0002129205 0.010657991 0.003137255
                Feature         Gain       Cover   Frequency
[1] "XGBoost Accuracy: 0.849581438147106"
Confusion Matrix and Statistics

          Reference
Prediction      0      1
         0 384808  30310
         1  50117  69453

               Accuracy : 0.8496
                 95% CI : (0.8486, 0.8505)
    No Information Rate : 0.8134
    P-Value [Acc > NIR] : < 2.2e-16

                  Kappa : 0.5397

 Mcnemar's Test P-Value : < 2.2e-16

            Sensitivity : 0.6962
            Specificity : 0.8848
         Pos Pred Value : 0.5809
         Neg Pred Value : 0.9270
             Prevalence : 0.1866
         Detection Rate : 0.1299
   Detection Prevalence : 0.2236
      Balanced Accuracy : 0.7905

       'Positive' Class : 1

r$> source("c:\\Users\\70254057\\Desktop\\basic-hub\\petit-rentier-HFCS
    \\prod\\ml_methods\\XGBoost-dummies.R", encoding = "UTF-8")
Garbage collection 84 = 45+8+31 (level 2) ...
123.1 Mbytes of cons cells used (54%)
34.5 Mbytes of vectors used (3%)
[1] "model type rentsbi_pens"
[1] "########################--------------------------------------------------------------########################"
                Feature         Gain       Cover   Frequency
                 <char>        <num>       <num>       <num>
 1:        class_Worker 0.1724999294 0.011411256 0.036097561
 2:           sa0100_FI 0.1692597251 0.042075909 0.017560976
 3:              otherp 0.1609583121 0.059133177 0.059512195
 4:      class_Inactive 0.0784175130 0.034496495 0.032975610
 5:            age_0-29 0.0506454464 0.029441769 0.021853659
 6:           age_30-49 0.0360514709 0.029940521 0.038243902
 7:           sa0100_NL 0.0316825814 0.028812253 0.014829268
 8:             age_+70 0.0313958922 0.028681297 0.038439024
 9:               hsize 0.0311281214 0.127457186 0.176975610
10:           age_50-69 0.0281707971 0.012756507 0.032975610
11:           sa0100_DE 0.0274987751 0.022578318 0.012292683
12:    edu_ref_tertiary 0.0244047542 0.019848746 0.036682927
13:             homeown 0.0227965953 0.032135896 0.065951220
14:           sa0100_IE 0.0218544701 0.015469939 0.007414634
15:           sa0100_ES 0.0125707838 0.012393437 0.012487805
16:           sa0100_PL 0.0091955564 0.030680973 0.006439024
17:          head_gendr 0.0078628052 0.043425997 0.066341463
18:     edu_ref_primary 0.0074972355 0.026199318 0.026926829
19:           sa0100_IT 0.0072570134 0.025073673 0.011317073
20:           sa0100_EE 0.0072377739 0.023456480 0.009951220
21:           sa0100_SK 0.0071587479 0.032165114 0.005853659
22:              wave_2 0.0066968876 0.015740388 0.035121951
23:           sa0100_GR 0.0065163881 0.022289889 0.007024390
24:           sa0100_HU 0.0062456463 0.028988682 0.016000000
25:           sa0100_SI 0.0042568838 0.021281671 0.008390244
26:           sa0100_BE 0.0038423630 0.010986825 0.007219512
27:           sa0100_LV 0.0037253662 0.021019206 0.006829268
28:   edu_ref_secondary 0.0037245726 0.021163030 0.039804878
36:           sa0100_AT 0.0012130637 0.012759419 0.007609756
37:           sa0100_CY 0.0009991434 0.013097787 0.005073171
38:           sa0100_PT 0.0009729492 0.012480366 0.008975610
39:           sa0100_HR 0.0008166515 0.015131653 0.006048780
40:      class_Employer 0.0003461527 0.013801545 0.003707317
41: class_Self-Employed 0.0002667265 0.012133687 0.003512195
                Feature         Gain       Cover   Frequency
[1] "XGBoost Accuracy: 0.865192411275361"
Confusion Matrix and Statistics

          Reference
Prediction      0      1
         0 403157  31995
         1  40085  59451

               Accuracy : 0.8652
                 95% CI : (0.8643, 0.8661)
    No Information Rate : 0.829
    P-Value [Acc > NIR] : < 2.2e-16

                  Kappa : 0.5407

 Mcnemar's Test P-Value : < 2.2e-16

            Sensitivity : 0.6501
            Specificity : 0.9096
         Pos Pred Value : 0.5973
         Neg Pred Value : 0.9265
             Prevalence : 0.1710
         Detection Rate : 0.1112
   Detection Prevalence : 0.1862
      Balanced Accuracy : 0.7798

       'Positive' Class : 1

r$> source("c:\\Users\\70254057\\Desktop\\basic-
    hub\\petit-rentier-HFCS\\prod\\ml_methods\\X
    GBoost-dummies.R", encoding = "UTF-8")
Garbage collection 120 = 61+15+44 (level 2) ...
123.1 Mbytes of cons cells used (54%)
34.5 Mbytes of vectors used (2%)
[1] "model type rentsbi"
[1] "########################--------------------------------------------------------------########################"
                Feature         Gain
                 <char>        <num>
 1:              otherp 0.5253724152
 2:               hsize 0.0418391176
 3:           sa0100_DE 0.0405409270
 4:           sa0100_ES 0.0357019809
 5:    edu_ref_tertiary 0.0305013909
 6:             age_+70 0.0288109970
 7:             homeown 0.0250107997
 8:      class_Inactive 0.0216684418
 9:              wave_2 0.0158220126
10:           sa0100_BE 0.0152745768
11:           age_30-49 0.0140461245
12:           sa0100_EE 0.0133107341
13:     edu_ref_primary 0.0128306651
14:              wave_1 0.0120931941
15:           sa0100_PL 0.0119458299
16:           sa0100_HU 0.0116766932
17:           sa0100_SI 0.0113787380
18:           sa0100_SK 0.0110603900
19:           sa0100_FI 0.0101771140
20:          head_gendr 0.0101155294
21:           sa0100_IT 0.0094016605
22:        class_Worker 0.0092321587
23:           sa0100_GR 0.0085394171
24:   edu_ref_secondary 0.0064107818
25:           age_50-69 0.0059340140
26:              wave_3 0.0058503674
27:            age_0-29 0.0058025020
28:           sa0100_LV 0.0053620081
29:           sa0100_CY 0.0053496494
30:       class_Manager 0.0053313546
31:           sa0100_MT 0.0053271417
32:           sa0100_IE 0.0053082636
33:           sa0100_LU 0.0049358359
34:              wave_4 0.0040719944
35:           sa0100_PT 0.0038528536
36:           sa0100_LT 0.0035470011
37:           sa0100_AT 0.0023675187
38:           sa0100_HR 0.0012655186
39:           sa0100_NL 0.0010251321
40:      class_Employer 0.0010172639
41: class_Self-Employed 0.0008898908
                Feature         Gain
          Cover   Frequency
          <num>       <num>
 1: 0.068892036 0.066878349
 2: 0.130396075 0.198650526
 3: 0.022616914 0.007541179
 4: 0.019499954 0.016669974
 5: 0.030664778 0.041079579
 6: 0.024179676 0.035522921
 7: 0.041058042 0.053978964
 8: 0.017444024 0.030561619
 9: 0.019280125 0.038896606
10: 0.020222703 0.009128795
11: 0.022545985 0.033736853
12: 0.025277000 0.007938083
13: 0.025491854 0.025600318
14: 0.028036681 0.024608057
15: 0.027336299 0.006350466
16: 0.030536689 0.012899385
17: 0.026177685 0.007541179
18: 0.023234791 0.006747371
19: 0.028068398 0.012304029
20: 0.034074565 0.062909307
21: 0.025341901 0.011510220
22: 0.005966615 0.033339948
23: 0.020230995 0.008533439
24: 0.020496590 0.038896606
25: 0.018533057 0.029569359
26: 0.006020418 0.028974003
27: 0.016646630 0.024608057
28: 0.025781903 0.005556658
29: 0.019287131 0.009128795
30: 0.017008968 0.018456043
31: 0.018437666 0.008731891
32: 0.017003069 0.005358206
33: 0.015062507 0.008731891
34: 0.007506866 0.025004961
35: 0.017389190 0.007739631
36: 0.020142493 0.003572137
37: 0.017663779 0.008136535
38: 0.009946733 0.005953562
39: 0.010354361 0.007144275
40: 0.011545508 0.006548918
41: 0.014599348 0.004961302
          Cover   Frequency
[1] "XGBoost Accuracy: 0.901127386438446"
Confusion Matrix and Statistics

          Reference
Prediction      0      1
         0 464506  30984
         1  21882  17316

               Accuracy : 0.9011
                 95% CI : (0.9003, 0.9019)
    No Information Rate : 0.9097
    P-Value [Acc > NIR] : 1

                  Kappa : 0.3426

 Mcnemar's Test P-Value : <2e-16

            Sensitivity : 0.35851
            Specificity : 0.95501
         Pos Pred Value : 0.44176
         Neg Pred Value : 0.93747
             Prevalence : 0.09033
         Detection Rate : 0.03239
   Detection Prevalence : 0.07331
      Balanced Accuracy : 0.65676

       'Positive' Class : 1
